{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UpSfBObsQrWo"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMTERS\n",
        "block=51\n",
        "batch=64\n",
        "n_embed=512\n",
        "iters=40000\n",
        "# lr=3e-5\n",
        "n_heads1=8\n",
        "n_layer=6\n",
        "dropout=0.1\n",
        "eval_iters=500\n",
        "# vocab_size=\n",
        "factor=4\n",
        "maxlen=50\n",
        "#------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ua2IeEM3QtIU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as f\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO378yAB6_mk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"kaitchup/opus-English-to-French\")\n",
        "#raw_datasets.cache_files\n",
        "for split, dataset in raw_datasets.items():\n",
        "    dataset.to_csv(f\"my-dataset-{split}.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CCUp_IbGQvNR"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv(\"my-dataset-train.csv\")\n",
        "val=pd.read_csv('my-dataset-validation.csv')\n",
        "train[['english','french']]=train['text'].str.split('###>',expand=True)\n",
        "val[['english','french']]=val['text'].str.split('###>',expand=True)\n",
        "traininput=train['english'].tolist()\n",
        "valinput=val['english'].tolist()\n",
        "trainoutput=train['french'].tolist()\n",
        "valoutput=val['french'].tolist()\n",
        "del train,val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M4vRazseQ4NN"
      },
      "outputs": [],
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qrC2QiA_YVO3"
      },
      "outputs": [],
      "source": [
        "inputtokenizertext=str(traininput[:10000])\n",
        "outputtokenizertext=str(trainoutput[:10000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rIiX4ZKmIm3S"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TOKENIZER TRAINING\n",
        "\n",
        "def check_stats(tokens):\n",
        "\n",
        "  stats={}\n",
        "  for i,b in zip(tokens,tokens[1:]):\n",
        "    stats[(i,b)]=stats.get((i,b),0)+1\n",
        "  return stats\n",
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids\n",
        "# len(merge(a))\n",
        "def createmerge(text,max_vocab):\n",
        "  tokens=text.encode('utf-8')\n",
        "  tokens=list(map(int,tokens))\n",
        "  ids = list(tokens)\n",
        "  merges={}\n",
        "  num_merges=max_vocab-255\n",
        "\n",
        "  for i in range(num_merges):\n",
        "    stats = check_stats(ids)\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 256 + i\n",
        "    #print(f\"merging {pair} into a new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx\n",
        "  return merges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U4IpBy1eYVO4"
      },
      "outputs": [],
      "source": [
        "inputmerges=createmerge(inputtokenizertext,1000)\n",
        "outputmerges=createmerge(outputtokenizertext,1000)\n",
        "inputvocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "outputvocab={idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in inputmerges.items():\n",
        "    inputvocab[idx] = inputvocab[p0] + inputvocab[p1]\n",
        "\n",
        "for (p0, p1), idx in outputmerges.items():\n",
        "    outputvocab[idx] = outputvocab[p0] + outputvocab[p1]\n",
        "\n",
        "inputvocab[1001]=b'|padding|'\n",
        "inputvocab[1002]=b'|eot|'\n",
        "inputvocab[1003]=b'|start|'\n",
        "outputvocab[1001]=b'|padding|'\n",
        "outputvocab[1002]=b'|eot|'\n",
        "outputvocab[1003]=b'|start|'\n",
        "inputvocab_size=len(inputvocab)\n",
        "outputvocab_size=len(outputvocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(b' that', b'Con')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputvocab[500],outputvocab[600]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1004, 1004)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputvocab_size,outputvocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# inputfiles={\"inputmerges\":inputmerges,\"inputvocab\":inputvocab}\n",
        "# outputfiles={'outputmerges':outputmerges,\"outputvocab\":outputvocab}\n",
        "# inputfile=open(\"inputfile.dat\",\"wb\")\n",
        "# outputfile=open(\"outputfile.dat\",\"wb\")\n",
        "# pickle.dump(inputfiles,inputfile)\n",
        "# pickle.dump(outputfiles,outputfile)\n",
        "# inputfile.close()\n",
        "# outputfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yCJ7PlsbIrf5"
      },
      "outputs": [],
      "source": [
        "def encode(text,type=\"input\"):\n",
        "   # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  if type=='input':\n",
        "    merges=inputmerges\n",
        "  else:\n",
        "    merges=outputmerges\n",
        "  while len(tokens) >= 2:\n",
        "    stats = check_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "def decode(ids,type='input'):\n",
        "  # given ids (list of integers), return Python string\n",
        "  if type=='input':\n",
        "    vocab=inputvocab\n",
        "  else:\n",
        "    vocab=outputvocab\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text\n",
        "#vocab=501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RSjPSc8-lrAt"
      },
      "outputs": [],
      "source": [
        "data=[]\n",
        "for i in [\"train\",\"val\"]:\n",
        "  if i ==\"train\":\n",
        "    inp=traininput\n",
        "    out=trainoutput\n",
        "  else:\n",
        "    inp=valinput\n",
        "    out=valoutput\n",
        "  inp1,out1=[],[]\n",
        "  for r in range(len(inp)):\n",
        "    # print(r)\n",
        "    # print(len(encode(inp[r])))\n",
        "    if len(encode(inp[r],type='input'))<=50 and len(encode(out[r],type='output'))<=50:\n",
        "      inp1+=[inp[r]]\n",
        "      out1+=[out[r]]\n",
        "  data+=[inp1,out1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w0FekLRj6_mk"
      },
      "outputs": [],
      "source": [
        "traininput1,trainoutput1,valinput1,valoutput1=data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beJZpTXw7RHJ"
      },
      "outputs": [],
      "source": [
        "# decode([1003]+encode(trainoutput1[1],type='output')+[1001]*(maxlen-len(encode(trainoutput1[1],type='outpout')))+[1002],type='output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqPPdcYttL-j",
        "outputId": "9c7b1ea7-bb0d-4b89-ee0e-25c4bf35acc5"
      },
      "outputs": [],
      "source": [
        "\n",
        "a=[max([len(encode(i)) for i in traininput1]),max([len(encode(i)) for i in trainoutput1]),max([len(encode(i)) for i in valinput1]),max([len(encode(i)) for i in valoutput1])]\n",
        "b=[len(encode(i)) for i in traininput1]+[len(encode(i)) for i in trainoutput1]+[len(encode(i)) for i in valinput1]+[len(encode(i)) for i in valoutput1]\n",
        "maxlen=max(a)\n",
        "maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWNGaJxb97j0",
        "outputId": "d31effc7-32af-452b-f049-ca7318d9c44c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7202, 7202, 522, 522)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(traininput1),len(trainoutput1),len(valinput1),len(valoutput1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Cz1Bu6OFkgg9",
        "outputId": "7235aeed-8148-4457-8da6-dae8b4ace26b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "def plot_occurrences(numbers):\n",
        "    # Count occurrences of each number in the list\n",
        "    count = Counter(numbers)\n",
        "\n",
        "    # Separate keys (numbers) and values (occurrences)\n",
        "    numbers = list(count.keys())\n",
        "    occurrences = list(count.values())\n",
        "\n",
        "    # Plot the data\n",
        "    plt.bar(numbers, occurrences)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Number')\n",
        "    plt.ylabel('Occurrences')\n",
        "    plt.title('Number of Occurrences of Numbers in the List')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "plot_occurrences(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xOjWRikHRAPX"
      },
      "outputs": [],
      "source": [
        "totraininput=[[1003]+encode(i,type='input')+[1001]*(maxlen-len(encode(i,type='input')))+[1002] for i in traininput1]\n",
        "totrainoutput=[[1003]+encode(i,type='output')+[1001]*(maxlen-len(encode(i,type='output')))+[1002] for i in trainoutput1]\n",
        "tovalinput=[[1003]+encode(i,type='input')+[1001]*(maxlen-len(encode(i,type='input')))+[1002] for i in valinput1]\n",
        "tovaloutput=[[1003]+encode(i,type='output')+[1001]*(maxlen-len(encode(i,type='output')))+[1002] for i in valoutput1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a=[totraininput,totrainoutput,tovalinput,tovaloutput]\n",
        "# import pickle\n",
        "# file=open(\"tokenized.dat\",\"wb\")\n",
        "# pickle.dump(a,file)\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1253"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(tovalinput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'|start|This Regulation shall enter into force on the seventh day following its publication in the Official Journal of the European Union. |padding||padding||padding||padding||padding||padding||padding||padding||padding||padding||eot|'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# file=open(\"tokenized.dat\",\"rb\")\n",
        "# a=pickle.load(file)\n",
        "# totraininput1=a[0]\n",
        "# decode(totraininput[1],type='input')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1LpRTL27fJJ"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# file=open(\"/content/drive/MyDrive/data_for_translator/tokenizedinputs.dat\",\"rb\")\n",
        "# a=pickle.load(file)\n",
        "# file.close()\n",
        "# totrainoutput=a[\"totraininput\"]\n",
        "# totraininput=a[\"totrainoutput\"]\n",
        "# tovaloutput=a[\"tovalinput\"]\n",
        "# tovalinput=a[\"tovaloutput\"]\n",
        "# file=open(\"/content/drive/MyDrive/data_for_translator/merges.dat\",\"rb\")\n",
        "# merges=pickle.load(file)\n",
        "# file.close()\n",
        "# file=open(\"/content/drive/MyDrive/data_for_translator/vocab.dat\",\"rb\")\n",
        "# vocab=pickle.load(file)\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv9a5xZ7RCM2"
      },
      "outputs": [],
      "source": [
        "def batches(split,batch,block):\n",
        "  data=[totraininput,totrainoutput] if split==\"train\" else [tovalinput,tovaloutput]\n",
        "  ix=torch.randint(len(data[0]),(batch,))\n",
        "  datain,dataoutput=data[0],data[1]\n",
        "  din=[datain[i] for i in ix]\n",
        "  dout=[dataoutput[i] for i in ix]\n",
        "  xin=torch.stack([torch.tensor(j[1:block]) for j in din])\n",
        "  xout=torch.stack([torch.tensor(j[2:block+1]) for j in din])\n",
        "  yin=torch.stack([torch.tensor(j[:block]) for j in dout])\n",
        "  yout=torch.stack([torch.tensor(j[1:block+1]) for j in dout])\n",
        "  xin,xout,yin,yout=xin.to(device),xout.to(device),yin.to(device),yout.to(device)\n",
        "  return xin,xout,yin,yout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXPhq1XS-D_T",
        "outputId": "53c8fac9-82ae-4d66-cd50-c59c3f58a8a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 50]),\n",
              " torch.Size([32, 50]),\n",
              " torch.Size([32, 51]),\n",
              " torch.Size([32, 51]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ein,eout,din,dout=batches(\"train\",32,51)\n",
        "ein.shape,eout.shape,din.shape,dout.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AczbPM6ERkE2"
      },
      "outputs": [],
      "source": [
        "class Differentiator(nn.Module):\n",
        "  def __init__(self,n_embed,heads):\n",
        "    super().__init__()     #n_embed is the embeddings after matching it with the embedding table and heads is the number of features\n",
        "    self.key=nn.Linear(n_embed,heads,bias=False)\n",
        "    self.query=nn.Linear(n_embed,heads,bias=False)\n",
        "    self.value=nn.Linear(n_embed,heads,bias=False)\n",
        "  def __call__(self,x):\n",
        "    key=self.key(x)\n",
        "    query=self.query(x)\n",
        "    value=self.value(x)    # B,N,T, HEADS\n",
        "    return [key,query,value]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pnlpy0yRg9e"
      },
      "outputs": [],
      "source": [
        "class Multiplier(nn.Module):\n",
        "  def __init__(self):    #batch, number,  block b,n,t\n",
        "    super().__init__()\n",
        "\n",
        "  def __call__(self,k,q,v,n_embed):\n",
        "      #B,T,HEADS\n",
        "    key,query=k,q\n",
        "    wei=query@key.transpose(-2,-1)*(n_embed**-0.5)  #B,N,T,T\n",
        "    return [wei,v]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlv_oLTOTuYD"
      },
      "outputs": [],
      "source": [
        "class Masking(nn.Module):\n",
        "  def __init__(self,block):\n",
        "    super().__init__()\n",
        "    self.register_buffer(\"tril\",torch.tril(torch.ones(block,block)))\n",
        "  def __call__(self,x):\n",
        "    B,T,C=x.shape\n",
        "    x=x.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph89bqO4TbUP"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self,n_embed,heads,block,dropout,mask=False):\n",
        "    super().__init__()\n",
        "    self.n_embed=n_embed\n",
        "    self.mult=Multiplier()\n",
        "    self.mask=Masking(block)\n",
        "    self.maskistrue=mask\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "  def __call__(self,k,q,v):\n",
        "\n",
        "    wei,v=self.mult(k,q,v,self.n_embed)\n",
        "    if self.maskistrue:\n",
        "      wei=self.mask(wei)\n",
        "\n",
        "    wei=f.softmax(wei,dim=-1)\n",
        "\n",
        "    wei=self.dropout(wei)\n",
        "    out =wei @ v\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAnndo34SNTl"
      },
      "outputs": [],
      "source": [
        "class MultipleHead(nn.Module):\n",
        "  def __init__(self,n_embed,heads,block,dropout,n_heads,mask=False):\n",
        "    super().__init__()\n",
        "    self.multihead=nn.ModuleList(Head(n_embed,heads,block,dropout,mask) for _ in range(n_heads))\n",
        "  def __call__(self,k,q,v):\n",
        "    return torch.cat([h(k,q,v) for h in self.multihead],dim=-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q8VbfULXPBw"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "   def __init__(self,n_embed,factor,dropout):    #factor is the ratio of the no of new neurons to the original\n",
        "      super().__init__()\n",
        "      self.net=nn.Sequential(nn.Linear(n_embed,factor*n_embed),\n",
        "                             nn.GELU(),\n",
        "                             nn.Linear(factor*n_embed,n_embed),\n",
        "                             nn.Dropout(dropout)\n",
        "      )\n",
        "   def __call__(self,x):\n",
        "        out=self.net(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdZx8m8iXiS9"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self,n_embed,factor,block,dropout,n_heads):\n",
        "    super().__init__()\n",
        "    self.lis=Differentiator(n_embed,n_embed//n_heads)\n",
        "    self.multihead=MultipleHead(n_embed,n_embed//n_heads,block,dropout,n_heads,mask=False)\n",
        "    self.ln1=nn.LayerNorm(n_embed)\n",
        "    self.ffd=FeedForward(n_embed,factor,dropout)\n",
        "    self.ln2=nn.LayerNorm(n_embed)\n",
        "  def __call__(self,x):\n",
        "    a=self.ln1(x)\n",
        "    k,q,v=self.lis(a)[0],self.lis(a)[1],self.lis(a)[2]\n",
        "    x=a+self.multihead(k,q,v)\n",
        "    x=self.ffd(self.ln2(x))+x\n",
        "    return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self,n_embed,factor,block,dropout,n_heads):\n",
        "    super().__init__()\n",
        "    self.lis=Differentiator(n_embed,n_embed//n_heads)\n",
        "    self.lis1=Differentiator(n_embed,n_embed//n_heads)\n",
        "    self.lis2=Differentiator(n_embed,n_embed//n_heads)\n",
        "    self.multihead=MultipleHead(n_embed,n_embed//n_heads,block,dropout,n_heads,mask=True)\n",
        "    self.multihead1=MultipleHead(n_embed,n_embed//n_heads,block,dropout,n_heads,mask=False)\n",
        "    self.ln1=nn.LayerNorm(n_embed)\n",
        "    self.ffd=FeedForward(n_embed,factor,dropout)\n",
        "    self.ln2=nn.LayerNorm(n_embed)\n",
        "  def __call__(self,c):\n",
        "\n",
        "    x,encodedata=c\n",
        "    a=self.ln1(x)\n",
        "    k,q,v=self.lis(a)[0],self.lis(a)[1],self.lis(a)[2]\n",
        "    x=a+self.multihead(k,q,v)\n",
        "    key,value=self.lis1(encodedata)[0],self.lis1(encodedata)[2]\n",
        "    query=self.lis2(x)[1]\n",
        "    x=x+self.multihead1(key,query,value)\n",
        "    x=self.ffd(self.ln2(x))+x\n",
        "    return [x,encodedata]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlu5vKWkRY9f"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "  #self,n_embed,factor,block,dropout,n_heads\n",
        "  def __init__(self,n_embed,factor,block,dropout,n_heads,n_layer):\n",
        "    super().__init__()\n",
        "    self.embed1=nn.Embedding(inputvocab_size,n_embed)\n",
        "    #self.posembed1=positional_encoding(block,n_embed)\n",
        "    #self.posembed=positional_encoding(block,n_embed)\n",
        "    self.posembed1=nn.Embedding(block,n_embed)\n",
        "    self.embed2=nn.Embedding(outputvocab_size,n_embed)\n",
        "    self.posembed2=nn.Embedding(block,n_embed)\n",
        "    self.linhead=nn.Linear(n_embed,outputvocab_size)\n",
        "    self.enc=nn.Sequential(*[EncoderBlock(n_embed=n_embed,n_heads=n_heads,factor=factor,block=block,dropout=dropout) for _ in range(n_layer)])\n",
        "    self.dec=nn.Sequential(*[DecoderBlock(n_embed=n_embed,n_heads=n_heads,factor=factor,block=block,dropout=dropout) for _ in range(n_layer)])\n",
        "    self.ln=nn.LayerNorm(n_embed)\n",
        "    self.ln1=nn.LayerNorm(n_embed)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.dropout1=nn.Dropout(dropout)\n",
        "  def __call__(self,encin,decin,decout=None):\n",
        "    B,T=encin.shape\n",
        "    b,t=decin.shape\n",
        "\n",
        "    enctokenembed=self.embed1(encin)  # b,t,cdevice\n",
        "    encposembed=self.posembed1(torch.arange(T,device=device))\n",
        "    xenc=enctokenembed+encposembed\n",
        "    xenc=self.dropout(xenc)\n",
        "    dectokenembed=self.embed2(decin)  # b,t,c\n",
        "    decposembed=self.posembed2(torch.arange(t,device=device))\n",
        "\n",
        "    xdec=dectokenembed+decposembed\n",
        "    xdec=self.dropout1(xdec)\n",
        "    encoutput=self.enc(xenc)\n",
        "    encoutput=self.ln(encoutput)\n",
        "    del enctokenembed,encposembed,xenc,dectokenembed,decposembed\n",
        "    decoutput=self.dec([xdec,encoutput])\n",
        "    decoutput=decoutput[0]\n",
        "    decoutput=self.ln1(decoutput)\n",
        "\n",
        "    logits=self.linhead(decoutput)  #b,t,vocab_size\n",
        "    del decoutput\n",
        "    b,t,c=logits.shape\n",
        "\n",
        "    if decout==None:\n",
        "      loss=None\n",
        "    else:\n",
        "      loss=f.cross_entropy(logits.reshape(b*t,-1),decout.reshape(-1))\n",
        "    return loss,logits\n",
        "  def generate(self,i):\n",
        "    ix=torch.ones((1,1),dtype=torch.long,device=device)*1003\n",
        "    a=torch.tensor([encode(i,type='input')+[1001]*(maxlen-len(encode(i,type='input')))])\n",
        "    a=a.to(device)\n",
        "    while ix[-1][-1]!=1002:\n",
        "      ix_cond=ix[:,-block:]\n",
        "\n",
        "      loss,logits=self(a,ix_cond)\n",
        "      # print(logits.shape)\n",
        "      logits=logits[:,-1,:]\n",
        "      probs=f.softmax(logits,dim=1)\n",
        "      #print(probs.shape)\n",
        "      idx_next=torch.multinomial(probs,num_samples=1)\n",
        "      #idx_next=idx_next.view(1,-1)\n",
        "      ix=torch.cat((ix,idx_next),dim=1)\n",
        "\n",
        "    return ix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUfGtRoF6_mn"
      },
      "outputs": [],
      "source": [
        "\n",
        "class lr_scheduler():\n",
        "    def __init__(self,n_embed,warmup_steps=4000):\n",
        "        self.n_embed=torch.tensor(n_embed,dtype=torch.float64)\n",
        "        self.warmup_steps=torch.tensor(warmup_steps,dtype=torch.float64)\n",
        "    def __call__(self,step):\n",
        "        step=torch.tensor(step,dtype=torch.float64)\n",
        "        #arg1=torch.sqrt(step)\n",
        "        #arg2=step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return self.n_embed**-0.5*torch.min(step**-0.5,step*self.warmup_steps**-1.5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mABAHmk7-s1Q"
      },
      "outputs": [],
      "source": [
        "a=lr_scheduler(n_embed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv-FDLb_6_mo"
      },
      "outputs": [],
      "source": [
        "# #most suitable hyperparamters found after sweeping are\n",
        "# lr=1e-4\n",
        "# n_embed=256\n",
        "# n_heads1=16\n",
        "# n_layer=6\n",
        "# block=51\n",
        "# batch=64\n",
        "# dropout=0.35\n",
        "# eval_iters=500\n",
        "# iters=20000\n",
        "# factor=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOXuPBwHvpzr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89SKXwbGpXrl",
        "outputId": "4c0fd666-ed44-4e16-99e3-018ab2fd3eba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embed1): Embedding(504, 512)\n",
              "  (posembed1): Embedding(51, 512)\n",
              "  (embed2): Embedding(504, 512)\n",
              "  (posembed2): Embedding(51, 512)\n",
              "  (linhead): Linear(in_features=512, out_features=504, bias=True)\n",
              "  (enc): Sequential(\n",
              "    (0): EncoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): EncoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): EncoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): EncoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): EncoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): EncoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (dec): Sequential(\n",
              "    (0): DecoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis1): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis2): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multihead1): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): DecoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis1): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis2): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multihead1): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): DecoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis1): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis2): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multihead1): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): DecoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis1): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis2): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multihead1): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): DecoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis1): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis2): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multihead1): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): DecoderBlock(\n",
              "      (lis): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis1): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (lis2): Differentiator(\n",
              "        (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "        (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "      )\n",
              "      (multihead): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multihead1): MultipleHead(\n",
              "        (multihead): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (mult): Multiplier()\n",
              "            (mask): Masking()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (dropout1): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m=Model(n_embed=n_embed,factor=factor,block=block,n_heads=n_heads1,n_layer=n_layer,dropout=dropout)\n",
        "#m.load_state_dict(torch.load(\"/content/drive/MyDrive/data_for_translator/model_val=0.9094.pt\"))\n",
        "m.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2KBtKVTw0_E"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "@torch.no_grad()\n",
        "def estimate_loss(batch,block,eval_iters,model):\n",
        "  out={}\n",
        "  model.eval()\n",
        "  print(\"estimating loss using functino\")\n",
        "  for split in ['train','val']:\n",
        "\n",
        "    losses=torch.zeros(eval_iters)\n",
        "    for k in tqdm(range(eval_iters)):\n",
        "      ein,eout,din,dout=batches(split,batch,block)\n",
        "      loss,logits=model(ein,din,dout)\n",
        "      losses[k] =loss.item()\n",
        "    out[split]=losses.mean()\n",
        "    print(out[split],\" \",split)\n",
        "  print(out)\n",
        "  model.train()\n",
        "  return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiROczZNxh5L"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "def training(lossl=None):\n",
        "  if lossl==None:\n",
        "    lossl=[]\n",
        "  else:\n",
        "    lossl=lossl\n",
        "  print(\"running on \",device)\n",
        "  for steps in tqdm(range(40000,80000)):\n",
        "    ein,eout,din,dout=batches(\"train\",batch=batch,block=block)\n",
        "    lr=a(steps)\n",
        "    optimizer = torch.optim.AdamW(m.parameters(), lr=lr,betas=(0.9,0.98),eps=1e-9)\n",
        "    loss,logits=m(ein,din,dout)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    lossl+=[loss.item()]\n",
        "    # if steps%eval_iters==0 or steps==iters-1:\n",
        "    #    estimate_loss(batch,block,eval_iters,m)\n",
        "    if steps%5000==0:\n",
        "      torch.save(m.state_dict(), f\"/content/drive/MyDrive/data_for_translator/model{steps}.pt\")\n",
        "\n",
        "    if steps%200==0 or steps==80000-1:\n",
        "\n",
        "      pl.plot(range(len(lossl)),lossl,color=\"red\")\n",
        "      pl.axhline(y=1, color='b', linestyle='--')\n",
        "      display.clear_output(wait=True)\n",
        "      display.display(pl.gcf())\n",
        "  torch.save(m.state_dict(), f\"/content/drive/MyDrive/data_for_translator/model{steps}.pt\")\n",
        "  return lossl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvV_pSQ2kgYk"
      },
      "outputs": [],
      "source": [
        "losses=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jEwtFY-6_mv",
        "outputId": "cc3fc3c2-900a-4cb6-9e7a-ee096abe7172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "estimating loss using functino\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:44<00:00, 11.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7248)   train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:39<00:00, 12.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.9094)   val\n",
            "{'train': tensor(0.7248), 'val': tensor(0.9094)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'train': tensor(0.7248), 'val': tensor(0.9094)}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "estimate_loss(batch,block,eval_iters,m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KrHG8GIS6_mv",
        "outputId": "e2bb1c93-2822-4eef-a44c-f68c04ec9b94"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Veuillez me prononc.\", \\'les enfof the s ?'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw=m.generate(\"How are you doing today?\")[-1].tolist()\n",
        "raw=[i for i in raw if i not in [502,501,503]]\n",
        "decode(raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o66X8Om6_mw",
        "outputId": "d3a4358f-68d5-49c4-bedf-90d431b8cb90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28409336"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(p.numel() for p in m.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjYteTyx6_mw"
      },
      "outputs": [],
      "source": [
        "# a={\"totraininput\":totraininput,\"totrainoutput\":totrainoutput,\"tovalinput\":tovalinput,\"tovaloutput\":tovaloutput}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X__fF4x76_mw"
      },
      "outputs": [],
      "source": [
        "# a={\"traininput\":traininput1,\"trainoutput\":trainoutput1,\"valinput\":valinput1,\"valoutput\":valoutput1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnEe18Jr6_mw"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# file=open(\"trimmedinputs.dat\",\"wb\")\n",
        "# pickle.dump(a,file)\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mRYbUAFxCZa"
      },
      "outputs": [],
      "source": [
        "# steps=53\n",
        "# torch.save(m.state_dict(), f\"/content/model_val=0.9094.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nQWhqCykwGQ"
      },
      "outputs": [],
      "source": [
        "torch.save(m.state_dict(), \"/content/model2.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BChcqQ4e6_mx"
      },
      "outputs": [],
      "source": [
        "#{'train': tensor(0.7658), 'val': tensor(1.4724)} when lr=3e-4 and embed is 256 iter= 2000 b=64\n",
        "#{'train': tensor(1.2398), 'val': tensor(1.5915)} when lr =2e-4 and embed is 128 iter =2000 b=32\n",
        "#{'train': tensor(1.1645), 'val': tensor(1.5469)} wehn lr =3e-4 and embed is 128 iter=2000 b=32\n",
        "#{'train': tensor(0.5140), 'val': tensor(1.5265)} when lr =3e-4 and embed is 256 iter =4000 b=64 overfit ho rha h yha\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tvh4F806Drg"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# vocabreader=open('vocab.dat','rb')\n",
        "# mergesreader=open('merges.dat','rb')\n",
        "# vocab=pickle.load(vocabreader)\n",
        "# merges=pickle.load(mergesreader)\n",
        "# vocab_size=len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFnvJ0LX6_mx"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "sweep_config={\n",
        "    'method':'random'\n",
        "}\n",
        "\n",
        "metric={\n",
        "    'name':'loss',\n",
        "    'goal':'minimize'\n",
        "\n",
        "}\n",
        "\n",
        "parameters_dict={\n",
        "    'batch':{\n",
        "        'values':[32,64,128]\n",
        "    },\n",
        "    'n_embed':{\n",
        "    'values':[32,64,128,512]\n",
        "    },\n",
        "    'n_heads':{\n",
        "        \"values\":[8,16]\n",
        "    },\n",
        "    'n_layers':{\n",
        "        'values':[4,6,8,10,12]\n",
        "    },\n",
        "    'dropout':{\n",
        "        'values':[0.2,0.3,0.35,0.4]\n",
        "    },\n",
        "    'factor':{\n",
        "        'values':[4,8]\n",
        "    },\n",
        "    'lr':{\n",
        "        'values':[4e-5,8e-5,1,1e-4,3e-4,7e-4,3e-3,1e-3]\n",
        "    }\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "parameters_dict.update({\n",
        "    'iters':{'value':2000},\n",
        "    'block':{'value':51},\n",
        "    'eval_iters':{\"value\":500}\n",
        "\n",
        "})\n",
        "sweep_config['parameters']=parameters_dict\n",
        "sweep_config['metric']=metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmEqak9H6_mx",
        "outputId": "d19e78fe-124f-4868-8e7d-f95752dc057d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
            " 'parameters': {'batch': {'values': [32, 64, 128]},\n",
            "                'block': {'value': 51},\n",
            "                'dropout': {'values': [0.2, 0.3, 0.35, 0.4]},\n",
            "                'eval_iters': {'value': 500},\n",
            "                'factor': {'values': [4, 8]},\n",
            "                'iters': {'value': 2000},\n",
            "                'lr': {'values': [4e-05,\n",
            "                                  8e-05,\n",
            "                                  1,\n",
            "                                  0.0001,\n",
            "                                  0.0003,\n",
            "                                  0.0007,\n",
            "                                  0.003,\n",
            "                                  0.001]},\n",
            "                'n_embed': {'values': [32, 64, 128, 512]},\n",
            "                'n_heads': {'values': [8, 16]},\n",
            "                'n_layers': {'values': [4, 6, 8, 10, 12]}}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pprint.pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkV0NXHr6_my",
        "outputId": "94e6a03f-4a62-4609-bf58-af33a9d5a660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 70wa861c\n",
            "Sweep URL: https://wandb.ai/abhyudayhari/uncategorized/sweeps/70wa861c\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "def training(config=None):\n",
        "  with wandb.init(config=config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "\n",
        "        #loader = build_dataset(config.batch_size)\n",
        "        m=Model(n_embed=config.n_embed,factor=config.factor,block=config.block,n_heads=config.n_heads,n_layer=config.n_layers,dropout=config.dropout)\n",
        "        m.to(device)\n",
        "        #network = build_network(config.fc_layer_size, config.dropout)\n",
        "        optimizer = torch.optim.AdamW(m.parameters(), lr=config.lr)\n",
        "        #optimizer = torch.optim.AdamW(config.optimizer, confi \"epoch\": epochg.learning_rate)\n",
        "        cum=[]\n",
        "        for epoch in tqdm(range(config.iters)):\n",
        "             ein,eout,din,dout=batches(\"train\",batch=config.batch,block=config.block)\n",
        "             loss,logits=m(ein,din,dout)\n",
        "             optimizer.zero_grad(set_to_none=True)\n",
        "             loss.backward()\n",
        "             cum+=[loss.item()]\n",
        "             optimizer.step()\n",
        "        cum=torch.tensor(cum,dtype=torch.float)\n",
        "        avgloss=cum.mean()\n",
        "        a=estimate_loss(batch=config.batch,block=config.block,eval_iters=config.eval_iters,model=m)\n",
        "        wandb.log({\"avgtrainingloss\":avgloss,\"loss\":float(a['val']),\"trainloss\":float(a['train'])})\n",
        "\n",
        "        #\n",
        "        #print(a)\n",
        "            #  avg_loss = train_epoch(network, loader, optimizer)\n",
        "        # wandb.log({\"loss\": float(a['val'])})\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeLvq4P56_my",
        "outputId": "5c31cd04-620a-49bf-b6fa-8cfa1b9e012a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "tensor(4.5000)\n"
          ]
        }
      ],
      "source": [
        "a=[i for i in range(10)]\n",
        "print(a)\n",
        "a=torch.tensor(a,dtype=torch.float)\n",
        "print(a.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwgFklwy6_my"
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id,training,count=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0nLyrJ66_my"
      },
      "outputs": [],
      "source": [
        "a=m.generate(\"Hi what were you doing yesterday\")[-1].tolist()\n",
        "a=[i for i in a if i not in [502,501,503]]\n",
        "decode(a)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
